<!DOCTYPE html><html><head><meta charset="utf-8"><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headeranchor-link {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  display: block;
  padding-right: 6px;
  padding-left: 30px;
  margin-left: -30px;
}

.markdown-body .headeranchor-link:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  position: relative;
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .headeranchor,
.markdown-body h2 .headeranchor,
.markdown-body h3 .headeranchor,
.markdown-body h4 .headeranchor,
.markdown-body h5 .headeranchor,
.markdown-body h6 .headeranchor {
  display: none;
  color: #000;
  vertical-align: middle;
}

.markdown-body h1:hover .headeranchor-link,
.markdown-body h2:hover .headeranchor-link,
.markdown-body h3:hover .headeranchor-link,
.markdown-body h4:hover .headeranchor-link,
.markdown-body h5:hover .headeranchor-link,
.markdown-body h6:hover .headeranchor-link {
  height: 1em;
  padding-left: 8px;
  margin-left: -30px;
  line-height: 1;
  text-decoration: none;
}

.markdown-body h1:hover .headeranchor-link .headeranchor,
.markdown-body h2:hover .headeranchor-link .headeranchor,
.markdown-body h3:hover .headeranchor-link .headeranchor,
.markdown-body h4:hover .headeranchor-link .headeranchor,
.markdown-body h5:hover .headeranchor-link .headeranchor,
.markdown-body h6:hover .headeranchor-link .headeranchor {
  display: inline-block;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* Multimarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px octicons-anchor;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\f05c';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><title>writeup</title></head><body><article class="markdown-body"><h1 id="traffic-sign-recognition"><strong>Traffic Sign Recognition</strong></h1>
<hr />
<p><strong>Build a Traffic Sign Recognition Project</strong></p>
<p>The goals / steps of this project are the following:<br />
<em> Load the data set (see below for links to the project data set)<br />
</em> Explore, summarize and visualize the data set<br />
<em> Design, train and test a model architecture<br />
</em> Use the model to make predictions on new images<br />
<em> Analyze the softmax probabilities of the new images<br />
</em> Summarize the results with a written report</p>
<h2 id="rubric-points"><a name="user-content-rubric-points" href="#rubric-points" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Rubric Points</h2>
<h3 id="here-i-consider-the-rubric-points-individually-and-describe-how-i-addressed-each-point-in-my-implementation"><a name="user-content-here-i-consider-the-rubric-points-individually-and-describe-how-i-addressed-each-point-in-my-implementation" href="#here-i-consider-the-rubric-points-individually-and-describe-how-i-addressed-each-point-in-my-implementation" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Here I consider the <a href="https://review.udacity.com/#!/rubrics/481/view">rubric points</a> individually and describe how I addressed each point in my implementation.</h3>
<h4 id="files-submitted"><a name="user-content-files-submitted" href="#files-submitted" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Files Submitted</h4>
<h5 id="submission-files"><a name="user-content-submission-files" href="#submission-files" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Submission Files</h5>
<p>All files are submitted except:</p>
<ul>
<li>The training-, validation- and test-set, which however can be downloaded by running the provided setup.py.</li>
<li>The tensorflow saved-model, which is too big for github. Similar result can however be achieved by running the code in the Jupyter notebook, then copy the model from training output to ./model/*</li>
</ul>
<h4 id="dataset-exploration"><a name="user-content-dataset-exploration" href="#dataset-exploration" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Dataset Exploration</h4>
<h5 id="dataset-summary"><a name="user-content-dataset-summary" href="#dataset-summary" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Dataset Summary</h5>
<p>The TrafficSignData module extracts the requested values.</p>
<h5 id="exploratory-visualization"><a name="user-content-exploratory-visualization" href="#exploratory-visualization" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Exploratory Visualization</h5>
<p>The TrafficSignData module show examples of each traffic sign label, along with the number of examples of each label in the training set.</p>
<h4 id="design-and-test-a-model-architecture"><a name="user-content-design-and-test-a-model-architecture" href="#design-and-test-a-model-architecture" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Design and Test a Model Architecture</h4>
<h5 id="preprocessing"><a name="user-content-preprocessing" href="#preprocessing" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Preprocessing</h5>
<p>I did only normalize the image data in the same way as was proposed in the description. There was also suggestions to gray-scale convert the image but I didn&rsquo;t see the point in doing that since it only removes information, and I think that&rsquo;s bad when there are no limits specified for the size of the model (e.g. in terms of number of weights or FLOPS).</p>
<h5 id="model-architecture"><a name="user-content-model-architecture" href="#model-architecture" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Model Architecture</h5>
<p>This is described both in Jupter notebook and this document.</p>
<h5 id="model-training"><a name="user-content-model-training" href="#model-training" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Model Training</h5>
<p>This is described both in Jupter notebook and this document.</p>
<h5 id="solution-approach"><a name="user-content-solution-approach" href="#solution-approach" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Solution Approach</h5>
<p>This is described both in Jupter notebook and this document.</p>
<h4 id="test-a-model-on-new-images"><a name="user-content-test-a-model-on-new-images" href="#test-a-model-on-new-images" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Test a Model on New Images</h4>
<h5 id="acquiring-new-images"><a name="user-content-acquiring-new-images" href="#acquiring-new-images" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Acquiring New Images</h5>
<p>There are five new images provided and some discussion about what&rsquo;s making it hard to classify them.</p>
<h5 id="performance-on-new-images"><a name="user-content-performance-on-new-images" href="#performance-on-new-images" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Performance on New Images</h5>
<p>The performance is provided and compared to the test set.</p>
<h5 id="model-certainty-softmax-probabilities"><a name="user-content-model-certainty-softmax-probabilities" href="#model-certainty-softmax-probabilities" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Model Certainty - Softmax Probabilities</h5>
<p>The top 5 soft-max score is measured for all new images and presented both in the Jupyter notebook and this document.</p>
<hr />
<h3 id="writeup-readme"><a name="user-content-writeup-readme" href="#writeup-readme" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Writeup / README</h3>
<h4 id="1-writeup-readme-that-includes-all-the-rubric-points-and-how-you-addressed-each-one"><a name="user-content-1-writeup-readme-that-includes-all-the-rubric-points-and-how-you-addressed-each-one" href="#1-writeup-readme-that-includes-all-the-rubric-points-and-how-you-addressed-each-one" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>1. Writeup / README that includes all the rubric points and how you addressed each one.</h4>
<p>You&rsquo;re reading it! and here is a link to my <a href="https://github.com/misaksson/self_driving_car_nd/tree/master/term1/CarND-Traffic-Sign-Classifier-Project/">project code</a></p>
<h3 id="data-set-summary-exploration"><a name="user-content-data-set-summary-exploration" href="#data-set-summary-exploration" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Data Set Summary &amp; Exploration</h3>
<h4 id="1-basic-summary-of-the-data-set"><a name="user-content-1-basic-summary-of-the-data-set" href="#1-basic-summary-of-the-data-set" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>1. Basic summary of the data set.</h4>
<p>I used the numpy library to calculate summary statistics of the traffic<br />
signs data set:</p>
<ul>
<li>The size of training set is 34799</li>
<li>The size of the validation set is 4410</li>
<li>The size of test set is 12630</li>
<li>The shape of a traffic sign image is (32, 32, 3)</li>
<li>The number of unique classes/labels in the data set is 43</li>
</ul>
<h4 id="2-exploratory-visualization-of-the-dataset"><a name="user-content-2-exploratory-visualization-of-the-dataset" href="#2-exploratory-visualization-of-the-dataset" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>2. Exploratory visualization of the dataset.</h4>
<p>Here is an exploratory visualization of the data set. It shows one example of each of the traffic signs in the data-set, along with the number of examples available in the training-set.</p>
<p><img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/writeup_images/exploratory_visualization.png" title="Exploratory Visualization" /></p>
<h3 id="design-and-test-a-model-architecture_1"><a name="user-content-design-and-test-a-model-architecture_1" href="#design-and-test-a-model-architecture_1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Design and Test a Model Architecture</h3>
<h4 id="1-image-data-preprocessing"><a name="user-content-1-image-data-preprocessing" href="#1-image-data-preprocessing" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>1. Image data preprocessing.</h4>
<p>As a first step, I decided to normalize the images to the range [-1, 1]. This was done in the same way for all images, just mapping the input range [0, 255] to [-1, 1]. The neural network needs it input centered, and close to 0 for effective training. I think it might have been better to instead normalize the images using the mean and standard deviation of each image, since that probably would make the model more robust for shifting light conditions.</p>
<p>Here is an example of a traffic sign image and its histogram before and after normalization.</p>
<p><img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/writeup_images/normalization.png" title="Normalization" /></p>
<p>I also decided to generate additional training data because the number of training examples was imbalanced, ranging from 180 to 2010 examples per class.</p>
<p>To add more data to the the data set, I oversampled the class-labels having fewer examples. I did not implement any augmentation of the oversampled images, they are just duplicated until the number of samples are equal. The reason that I didn&rsquo;t do any augmentation on these images was to avoid producing &ldquo;water-marks&rdquo; in the images e.g. at the image borders, which might make such errors necessary for the classifier to believe the image belongs to an less represented class-labels.</p>
<p>Instead the plan was to do augmentation in the next step and on all images of the oversampled set, which would balance the &ldquo;water-mark&rdquo; error equally for all classes. Unfortunately I didn&rsquo;t have time to test this.</p>
<h4 id="2-final-model-architecture"><a name="user-content-2-final-model-architecture" href="#2-final-model-architecture" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>2. Final model architecture</h4>
<p>My final model consisted of the following layers:</p>
<table>
<thead>
<tr>
<th align="center">Layer</th>
<th align="center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Input</td>
<td align="center">32x32x3 RGB image</td>
</tr>
<tr>
<td align="center">Convolution 7x7</td>
<td align="center">1x1 stride, valid padding, outputs 26x26x15</td>
</tr>
<tr>
<td align="center">RELU6</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Max pooling 2x2</td>
<td align="center">2x2 stride,  outputs 13x13x15</td>
</tr>
<tr>
<td align="center">Convolution 6x6</td>
<td align="center">1x1 stride, valid padding, outputs 8x8x49</td>
</tr>
<tr>
<td align="center">ELU</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Max pooling 2x2</td>
<td align="center">2x2 stride,  outputs 4x4x49</td>
</tr>
<tr>
<td align="center">Fully connected</td>
<td align="center">outputs 8362</td>
</tr>
<tr>
<td align="center">CRELU</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Fully connected</td>
<td align="center">outputs 811</td>
</tr>
<tr>
<td align="center">Dropout</td>
<td align="center">keep_prob 0.5</td>
</tr>
<tr>
<td align="center">Sigmoid</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Fully connected</td>
<td align="center">outputs 43</td>
</tr>
</tbody>
</table>
<h4 id="3-training-my-model"><a name="user-content-3-training-my-model" href="#3-training-my-model" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>3. Training my model.</h4>
<p>I did some experiments with the learning rate, trying to find a small value, that still was large enough to not get stuck at local minimums. The value I ended up with was 0.0004. If I would spend more time on this then I think implementing the learning rate using a tensor variable might be a good idea, since it makes it possible to use learning rate momentum.</p>
<p>I did not care much about the number of epochs, instead I just saved the model every time the validation accuracy reached a new maximum. By doing this, I somewhat avoid the risk of continuing the training too long, which would make the model overfit the training data and perform poorly at any unknown data.</p>
<h4 id="4-the-approach-taken-for-finding-a-solution-and-getting-the-validation-set-accuracy-to-be-at-least-093-include-in-the-discussion-the-results-on-the-training-validation-and-test-sets-and-where-in-the-code-these-were-calculated-your-approach-may-have-been-an-iterative-process-in-which-case-outline-the-steps-you-took-to-get-to-the-final-solution-and-why-you-chose-those-steps-perhaps-your-solution-involved-an-already-well-known-implementation-or-architecture-in-this-case-discuss-why-you-think-the-architecture-is-suitable-for-the-current-problem"><a name="user-content-4-the-approach-taken-for-finding-a-solution-and-getting-the-validation-set-accuracy-to-be-at-least-093-include-in-the-discussion-the-results-on-the-training-validation-and-test-sets-and-where-in-the-code-these-were-calculated-your-approach-may-have-been-an-iterative-process-in-which-case-outline-the-steps-you-took-to-get-to-the-final-solution-and-why-you-chose-those-steps-perhaps-your-solution-involved-an-already-well-known-implementation-or-architecture-in-this-case-discuss-why-you-think-the-architecture-is-suitable-for-the-current-problem" href="#4-the-approach-taken-for-finding-a-solution-and-getting-the-validation-set-accuracy-to-be-at-least-093-include-in-the-discussion-the-results-on-the-training-validation-and-test-sets-and-where-in-the-code-these-were-calculated-your-approach-may-have-been-an-iterative-process-in-which-case-outline-the-steps-you-took-to-get-to-the-final-solution-and-why-you-chose-those-steps-perhaps-your-solution-involved-an-already-well-known-implementation-or-architecture-in-this-case-discuss-why-you-think-the-architecture-is-suitable-for-the-current-problem" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>4. The approach taken for finding a solution and getting the validation set accuracy to be at least 0.93. Include in the discussion the results on the training, validation and test sets and where in the code these were calculated. Your approach may have been an iterative process, in which case, outline the steps you took to get to the final solution and why you chose those steps. Perhaps your solution involved an already well known implementation or architecture. In this case, discuss why you think the architecture is suitable for the current problem.</h4>
<p>My final model results were:<br />
<em> training set accuracy of 1.0<br />
</em> validation set accuracy of 0.962<br />
* test set accuracy of 0.944</p>
<p>This is calculated in the Jupyter notebook cell 15, 16 and 17.</p>
<p>The model was trained using a neural-network training framework that I implemented my self for this project. This allowed me to easily generate variants of the graph layout and its parameter settings, automatically alternating the configuration for each training session such that all possible permutations of the parameters are trained and evaluated. Unfortunately it took some time to implement this, so there was no time in the end to use it for any exhaustively evaluation of lots of settings. Instead I based my model on the LeNet-5 and tried some variants.</p>
<h5 id="activation-functions"><a name="user-content-activation-functions" href="#activation-functions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Activation functions</h5>
<p>I experimented with different activation functions. The result of this was that I ended up using different activation functions for each of the four layers (RELU6, ELU, CRELU and Sigmoid).</p>
<h5 id="convolutional-filter-size"><a name="user-content-convolutional-filter-size" href="#convolutional-filter-size" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Convolutional filter size</h5>
<p>I also evaluated different filter sizes in the convolutional layers, ending up with best result using 7x7 resp. 6x6. I think removing the max-pool layers and trying larger filter sizes might give better result. Probably also adding more output channels.</p>
<h5 id="l2-loss-regularizatoin"><a name="user-content-l2-loss-regularizatoin" href="#l2-loss-regularizatoin" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>L2 loss regularizatoin</h5>
<p>Another thing I was experimenting with was L2 loss regularization, which helps to avoid overfitting the model. In the final model this did however produce worse result, so I set the beta value to 0.</p>
<h5 id="dropout"><a name="user-content-dropout" href="#dropout" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Dropout</h5>
<p>Dropout makes the model more redundant since it can&rsquo;t rely on any particular data path. This did show good result and is included in the final model with a keep probability of 0.5, which however is the only value I tested.</p>
<h5 id="penalize-frequently-represented-class-labels"><a name="user-content-penalize-frequently-represented-class-labels" href="#penalize-frequently-represented-class-labels" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Penalize frequently represented class-labels</h5>
<p>By looking at the confusion matrix from an evaluation of the validation set, it was obvious that the unequal number of training examples for the different classes caused problems. In an attempt to counter this, I tried to penalize frequent class-labels by multiplying the output from the logits with a weighed class vector, that is before the softmax_cross_entropy operation. I was however unable to find a weight vector that produced good result with this method.</p>
<h5 id="oversampling-training-data"><a name="user-content-oversampling-training-data" href="#oversampling-training-data" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Oversampling training data</h5>
<p>Another method I tried to compensate for the imbalanced training data was to apply oversampling, where I simply duplicated the images of less frequent class-labels until the numbers are equal. This was successful and made the accuracy increase from around 0.94 to 0.96+.</p>
<h3 id="test-a-model-on-new-images_1"><a name="user-content-test-a-model-on-new-images_1" href="#test-a-model-on-new-images_1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Test a Model on New Images</h3>
<h4 id="1-choose-five-german-traffic-signs-found-on-the-web-and-provide-them-in-the-report-for-each-image-discuss-what-quality-or-qualities-might-be-difficult-to-classify"><a name="user-content-1-choose-five-german-traffic-signs-found-on-the-web-and-provide-them-in-the-report-for-each-image-discuss-what-quality-or-qualities-might-be-difficult-to-classify" href="#1-choose-five-german-traffic-signs-found-on-the-web-and-provide-them-in-the-report-for-each-image-discuss-what-quality-or-qualities-might-be-difficult-to-classify" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>1. Choose five German traffic signs found on the web and provide them in the report. For each image, discuss what quality or qualities might be difficult to classify.</h4>
<p>Here are five German traffic signs that I found on the web:</p>
<p><img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/data/additional/label4.jpg" title="Traffic Sign 1" /> <img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/data/additional/label7.jpg" title="Traffic Sign 2" /> <img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/data/additional/label12.jpg" title="Traffic Sign 3" /><br />
<img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/data/additional/label17.jpg" title="Traffic Sign 4" /> <img alt="alt text" src="/home/markus/files/courses/selfDrivingCar/projects/self_driving_car_nd/term1/CarND-Traffic-Sign-Classifier-Project/data/additional/label25.jpg" title="Traffic Sign 5" /></p>
<p>Non of the images I selected was very hard, they are all more or less directly from the front and the light conditions seems fine. The background are not too annoying, and I didn&rsquo;t choose any of the less frequently represented images, or the ones that almost look the same.</p>
<p>But in general, speed signs might be hard because there are several types of them that only differ by the number. There are also several warning signs that look somewhat similar. The priority road sign is however very unique and should typically not be of any problem.</p>
<h4 id="2-predictions-on-the-new-traffic-signs-compared-to-the-test-set"><a name="user-content-2-predictions-on-the-new-traffic-signs-compared-to-the-test-set" href="#2-predictions-on-the-new-traffic-signs-compared-to-the-test-set" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>2. Predictions on the new traffic signs compared to the test set.</h4>
<p>Here are the results of the prediction:</p>
<table>
<thead>
<tr>
<th align="center">Image</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">70 km/h</td>
<td align="center">70 km/h</td>
</tr>
<tr>
<td align="center">100 km/h</td>
<td align="center">100 km/h</td>
</tr>
<tr>
<td align="center">Priority road</td>
<td align="center">Priority road</td>
</tr>
<tr>
<td align="center">No entry</td>
<td align="center">No entry</td>
</tr>
<tr>
<td align="center">Road work</td>
<td align="center">Road work</td>
</tr>
</tbody>
</table>
<p>The model was able to correctly guess 5 of the 5 traffic signs, which gives an accuracy of 100%. This is better than the test set where the accuracy was 94.4%.</p>
<h4 id="3-how-certain-is-the-model-when-predicting-on-each-of-the-five-new-images"><a name="user-content-3-how-certain-is-the-model-when-predicting-on-each-of-the-five-new-images" href="#3-how-certain-is-the-model-when-predicting-on-each-of-the-five-new-images" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>3. How certain is the model when predicting on each of the five new images.</h4>
<p>The code for making predictions on my final model is located in the 22th cell of the Jupyter notebook.</p>
<p>The model is very certain for all images. All predictions are correct and the soft-max probability is never less than 0.95 (for the 70 km/h sign, all the other signs have probabilities above 0.98).</p>
<h5 id="image-1-70-kmh"><a name="user-content-image-1-70-kmh" href="#image-1-70-kmh" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Image 1 (70 km/h)</h5>
<table>
<thead>
<tr>
<th align="center">Probability</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">.95</td>
<td align="center">70 km/h</td>
</tr>
<tr>
<td align="center">.03</td>
<td align="center">20 km/h</td>
</tr>
<tr>
<td align="center">.01</td>
<td align="center">30 km/h</td>
</tr>
<tr>
<td align="center">.00</td>
<td align="center">General caution</td>
</tr>
<tr>
<td align="center">.00</td>
<td align="center">60 km/h</td>
</tr>
</tbody>
</table>
<h5 id="image-2-100-kmh"><a name="user-content-image-2-100-kmh" href="#image-2-100-kmh" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Image 2 (100 km/h)</h5>
<table>
<thead>
<tr>
<th align="center">Probability</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">.98</td>
<td align="center">100 km/h</td>
</tr>
<tr>
<td align="center">.007</td>
<td align="center">Vehicles over 3.5 metric tons prohibited</td>
</tr>
<tr>
<td align="center">.005</td>
<td align="center">80 km/h</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">120 km/</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">No passing for vehicles over 3.5 metric tons</td>
</tr>
</tbody>
</table>
<h5 id="image-3-priority-road"><a name="user-content-image-3-priority-road" href="#image-3-priority-road" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Image 3 (Priority road)</h5>
<table>
<thead>
<tr>
<th align="center">Probability</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1.00</td>
<td align="center">Priority road</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">No passing for vehicles over 3.5 metric tons</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Traffic signals</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Stop</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">No entry</td>
</tr>
</tbody>
</table>
<h5 id="image-4-no-entry"><a name="user-content-image-4-no-entry" href="#image-4-no-entry" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Image 4 (No entry)</h5>
<table>
<thead>
<tr>
<th align="center">Probability</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">.997</td>
<td align="center">No entry</td>
</tr>
<tr>
<td align="center">.002</td>
<td align="center">Stop</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">No passing</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Yield</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">60 km/h</td>
</tr>
</tbody>
</table>
<h5 id="image-5-road-work"><a name="user-content-image-5-road-work" href="#image-5-road-work" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Image 5 (Road work)</h5>
<table>
<thead>
<tr>
<th align="center">Probability</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1.00</td>
<td align="center">Road work</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Beware of ice/snow</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Dangerous curve to the right</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Right-of-way at the next intersection</td>
</tr>
<tr>
<td align="center">.000</td>
<td align="center">Pedestrians</td>
</tr>
</tbody>
</table></article></body></html>